{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-22T04:59:04.336862400Z",
     "start_time": "2024-06-22T04:59:03.627766400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PCA_and_ETC import read_and_preprocess_data, generate_PCA_Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sp = pd.read_csv('../Database/ETC/sp500.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T05:02:11.783116700Z",
     "start_time": "2024-06-22T05:02:11.768564400Z"
    }
   },
   "id": "735e781364432583",
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "sp = yf.download('^GSPC', start='1990-01-01')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T05:01:32.160109600Z",
     "start_time": "2024-06-22T05:01:31.234517500Z"
    }
   },
   "id": "ab3b7f8724b42354",
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[110], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m sp_monthly \u001B[38;5;241m=\u001B[39m sp\u001B[38;5;241m.\u001B[39mresample(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mM\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mlast()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Pairs_Trading\\Lib\\site-packages\\pandas\\core\\generic.py:9771\u001B[0m, in \u001B[0;36mNDFrame.resample\u001B[1;34m(self, rule, axis, closed, label, convention, kind, on, level, origin, offset, group_keys)\u001B[0m\n\u001B[0;32m   9768\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   9769\u001B[0m     convention \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstart\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 9771\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m get_resampler(\n\u001B[0;32m   9772\u001B[0m     cast(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSeries | DataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m   9773\u001B[0m     freq\u001B[38;5;241m=\u001B[39mrule,\n\u001B[0;32m   9774\u001B[0m     label\u001B[38;5;241m=\u001B[39mlabel,\n\u001B[0;32m   9775\u001B[0m     closed\u001B[38;5;241m=\u001B[39mclosed,\n\u001B[0;32m   9776\u001B[0m     axis\u001B[38;5;241m=\u001B[39maxis,\n\u001B[0;32m   9777\u001B[0m     kind\u001B[38;5;241m=\u001B[39mkind,\n\u001B[0;32m   9778\u001B[0m     convention\u001B[38;5;241m=\u001B[39mconvention,\n\u001B[0;32m   9779\u001B[0m     key\u001B[38;5;241m=\u001B[39mon,\n\u001B[0;32m   9780\u001B[0m     level\u001B[38;5;241m=\u001B[39mlevel,\n\u001B[0;32m   9781\u001B[0m     origin\u001B[38;5;241m=\u001B[39morigin,\n\u001B[0;32m   9782\u001B[0m     offset\u001B[38;5;241m=\u001B[39moffset,\n\u001B[0;32m   9783\u001B[0m     group_keys\u001B[38;5;241m=\u001B[39mgroup_keys,\n\u001B[0;32m   9784\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Pairs_Trading\\Lib\\site-packages\\pandas\\core\\resample.py:2050\u001B[0m, in \u001B[0;36mget_resampler\u001B[1;34m(obj, kind, **kwds)\u001B[0m\n\u001B[0;32m   2046\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2047\u001B[0m \u001B[38;5;124;03mCreate a TimeGrouper and return our resampler.\u001B[39;00m\n\u001B[0;32m   2048\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2049\u001B[0m tg \u001B[38;5;241m=\u001B[39m TimeGrouper(obj, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m-> 2050\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tg\u001B[38;5;241m.\u001B[39m_get_resampler(obj, kind\u001B[38;5;241m=\u001B[39mkind)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Pairs_Trading\\Lib\\site-packages\\pandas\\core\\resample.py:2272\u001B[0m, in \u001B[0;36mTimeGrouper._get_resampler\u001B[1;34m(self, obj, kind)\u001B[0m\n\u001B[0;32m   2263\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ax, TimedeltaIndex):\n\u001B[0;32m   2264\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m TimedeltaIndexResampler(\n\u001B[0;32m   2265\u001B[0m         obj,\n\u001B[0;32m   2266\u001B[0m         timegrouper\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2269\u001B[0m         gpr_index\u001B[38;5;241m=\u001B[39max,\n\u001B[0;32m   2270\u001B[0m     )\n\u001B[1;32m-> 2272\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m   2273\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOnly valid with DatetimeIndex, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2274\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTimedeltaIndex or PeriodIndex, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2275\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut got an instance of \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(ax)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2276\u001B[0m )\n",
      "\u001B[1;31mTypeError\u001B[0m: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'"
     ]
    }
   ],
   "source": [
    "sp_monthly = sp.resample('M').last()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T05:04:53.103608700Z",
     "start_time": "2024-06-22T05:04:52.487144700Z"
    }
   },
   "id": "812d954a626d8bbe",
   "execution_count": 110
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "index = sp_monthly['Adj Close'].pct_change().dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T05:04:53.111672400Z",
     "start_time": "2024-06-22T05:04:53.106112900Z"
    }
   },
   "id": "51d998846c81c84d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "index=index.apply(lambda x: np.log(x+1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T05:01:38.842876900Z",
     "start_time": "2024-06-22T05:01:38.830896Z"
    }
   },
   "id": "1c338511d1b95843",
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "col = ['06/1999-12/1999', '01/2000-12/2002(9/11)', '01/2003-12/2006', '01/2007-12/2009(GFC)',\n",
    "       '01/2010-12/2019', '01/2020-12/2022(Covid-19)', 'Overall']\n",
    "\n",
    "period = [range(0, 119), range(119, 155), range(155, 203), range(203, 239), range(239, 359), range(359, 391),\n",
    "          range(0, 391)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T05:01:39.412999100Z",
     "start_time": "2024-06-22T05:01:39.402379800Z"
    }
   },
   "id": "9d2cfd81013b925f",
   "execution_count": 103
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "row=index.T.iloc[range(203, 239)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T05:07:04.436968900Z",
     "start_time": "2024-06-22T05:07:04.426999900Z"
    }
   },
   "id": "7433ce414d9b74f6",
   "execution_count": 123
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "returns = np.exp(np.mean(row) *5.4)-1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T05:07:27.726016700Z",
     "start_time": "2024-06-22T05:07:27.717504700Z"
    }
   },
   "id": "48cfdd91b6d3764d",
   "execution_count": 132
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "-0.03543421351437548"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T05:07:28.182251700Z",
     "start_time": "2024-06-22T05:07:28.176729200Z"
    }
   },
   "id": "6afe0da05006a020",
   "execution_count": 133
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "index.T.to_csv('../Database/ETC/sp500_return.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T04:32:01.309919400Z",
     "start_time": "2024-06-22T04:32:01.300806600Z"
    }
   },
   "id": "9aeb5826a683e786",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PCA_and_ETC import read_and_preprocess_data, generate_PCA_Data\n",
    "\n",
    "cl_list = ['60_characteristics_us', '70_characteristics_us', '80_characteristics_us', '90_characteristics_us']\n",
    "# cl_list = [f'{i}_characteristics_us' for i in range(10, 80, 10)]\n",
    "for a in cl_list:\n",
    "    input_dir = f'../Database/Clustering_Result/Contrastive_Learning/{a}'\n",
    "    input_dir2 = f'../Database/Clustering_Result/Contrastive_Learning/Prob/{a}'\n",
    "    output_dir = f'../Database/Clustering_Result/Contrastive_Learning/CL_Pre/{a}'\n",
    "\n",
    "    files = sorted(filename for filename in os.listdir(input_dir))\n",
    "\n",
    "    for file in files:\n",
    "        data = read_and_preprocess_data(input_dir, file)\n",
    "        prob = read_and_preprocess_data(input_dir2, file)\n",
    "        prob.index = prob['firms']\n",
    "        prob = prob.drop(columns='firms')\n",
    "        prob_filtered = prob[(prob.max(axis=1) <= prob.max(axis=1).quantile(0.80))]\n",
    "        data.loc[prob_filtered.index, 'clusters'] = 0\n",
    "        data.to_csv(os.path.join(output_dir, file))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T13:58:29.239076Z",
     "start_time": "2024-06-21T13:57:27.983590500Z"
    }
   },
   "id": "fe894ae54083ca12",
   "execution_count": 135
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_characteristics_us\n",
      "0    759.379139\n",
      "dtype: float64\n",
      "20_characteristics_us\n",
      "0    757.98723\n",
      "dtype: float64\n",
      "30_characteristics_us\n",
      "0    757.904674\n",
      "dtype: float64\n",
      "40_characteristics_us\n",
      "0    757.921769\n",
      "dtype: float64\n",
      "50_characteristics_us\n",
      "0    757.500136\n",
      "dtype: float64\n",
      "60_characteristics_us\n",
      "0    760.097656\n",
      "dtype: float64\n",
      "70_characteristics_us\n",
      "0    761.83405\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_dir = '../Database/Clustering_Result/Contrastive_Learning2/CL_pre'\n",
    "input_dir2 = '../Database/characteristics_US'\n",
    "subdirectories = [d for d in os.listdir(input_dir)]\n",
    "\n",
    "for subdir in subdirectories:\n",
    "    base_directory = f'{input_dir}/{subdir}'\n",
    "    files = sorted(filename for filename in os.listdir(base_directory) if filename.endswith('.csv'))\n",
    "\n",
    "    bic_dict = {}\n",
    "\n",
    "    for file in files:\n",
    "        df = read_and_preprocess_data(base_directory, file)\n",
    "        df2 = read_and_preprocess_data(input_dir2, file)\n",
    "        df2 = generate_PCA_Data(df2)\n",
    "\n",
    "        n = df.shape[0]\n",
    "        d = df2.shape[1]\n",
    "\n",
    "        clusters = {}\n",
    "        total_length = 0\n",
    "        for j in range(1 + max(set(df['clusters']))):\n",
    "            # if j == 0:\n",
    "            #     continue\n",
    "            cluster_data = df2.loc[df[df['clusters'] == j].index, 'mom1':]\n",
    "\n",
    "            # 각 클러스터에 대하여 정규화된 특성들의 var의 평균을 구함\n",
    "            clusters[j] = cluster_data.var().mean()\n",
    "\n",
    "        # total variance는 클러스터 전체의 var의 평균을 사용.\n",
    "        total_variance = pd.DataFrame(clusters.values()).sum()\n",
    "\n",
    "        # 최대 가능도\n",
    "        L = np.exp(-0.5 * total_variance)\n",
    "        # 모델의 자유도\n",
    "        k = len(clusters)-1\n",
    "        v = d + np.log(n/k)\n",
    "        # BIC 계산\n",
    "        bic = -2 * np.log(L) + v * np.log(n)\n",
    "        bic_dict[file] = bic\n",
    "\n",
    "    print(subdir)\n",
    "    # 전체기간에 대하여 bic score의 평균을 구함\n",
    "    a = pd.DataFrame(bic_dict.values()).mean()\n",
    "    print(a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T03:50:20.858986100Z",
     "start_time": "2024-06-22T03:44:53.318826600Z"
    }
   },
   "id": "c8fe72df78b95063",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PCA_and_ETC import read_and_preprocess_data, generate_PCA_Data\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# 클러스터 내 최대 거리 계산 함수\n",
    "def intra_cluster_distance(data, labels, cluster):\n",
    "    cluster_points = data[labels == cluster]\n",
    "    if len(cluster_points) <= 1:\n",
    "        return 0\n",
    "    return np.max(pairwise_distances(cluster_points))\n",
    "\n",
    "# 클러스터 간 최소 거리 계산 함수\n",
    "def inter_cluster_distance(cluster_centers):\n",
    "    if len(cluster_centers) <= 1:\n",
    "        return 0\n",
    "    distances = pairwise_distances(cluster_centers)\n",
    "    np.fill_diagonal(distances, np.inf)  # 자신과의 거리를 무한대로 설정하여 최소 거리를 올바르게 계산\n",
    "    return np.min(distances)\n",
    "\n",
    "# Dunn Index 계산 함수\n",
    "def dunn_index(data, labels):\n",
    "    unique_clusters = np.unique(labels)\n",
    "    cluster_centers = np.array([data[labels == cluster].mean(axis=0) for cluster in unique_clusters])\n",
    "    \n",
    "    intra_distances = [intra_cluster_distance(data, labels, cluster) for cluster in unique_clusters]\n",
    "    inter_distance = inter_cluster_distance(cluster_centers)\n",
    "    \n",
    "    return inter_distance / np.max(intra_distances)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T03:32:40.554908700Z",
     "start_time": "2024-06-22T03:32:40.549708Z"
    }
   },
   "id": "d8806452a53eb6e8",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0    0.023543\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PCA_and_ETC import read_and_preprocess_data, generate_PCA_Data\n",
    "\n",
    "input_dir = '../Database/Clustering_Result/DBSCAN'\n",
    "input_dir2 = '../Database/characteristics_US'\n",
    "subdirectories = [d for d in os.listdir(input_dir)]\n",
    "\n",
    "for subdir in subdirectories:\n",
    "    base_directory = f'{input_dir}/{subdir}'\n",
    "    files = sorted(filename for filename in os.listdir(base_directory) if filename.endswith('.csv'))\n",
    "\n",
    "    dunn_dict = {}\n",
    "\n",
    "    for file in files:\n",
    "        df = read_and_preprocess_data(base_directory, file)\n",
    "        df2 = read_and_preprocess_data(input_dir2, file)\n",
    "        df2 = generate_PCA_Data(df2)\n",
    "\n",
    "        # 원본 벡터와 클러스터 레이블을 결합\n",
    "        data = df2.to_numpy()\n",
    "        labels = df['clusters'].to_numpy()\n",
    "        \n",
    "        # Dunn Index 계산\n",
    "        dunn_dict[file] = dunn_index(data, labels)\n",
    "\n",
    "    print(subdir)\n",
    "    # 전체기간에 대하여 dunn의 평균을 구함\n",
    "    a = pd.DataFrame(dunn_dict.values()).mean()\n",
    "    print(a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T03:40:11.012485300Z",
     "start_time": "2024-06-22T03:39:06.862532400Z"
    }
   },
   "id": "8d68e8980ce58712",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_characteristics_us\n",
      "0   -0.205846\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PCA_and_ETC import read_and_preprocess_data, generate_PCA_Data\n",
    "from sklearn.metrics import silhouette_score\n",
    "input_dir = '../Database/Clustering_Result/Contrastive_Learning2/CL_pre'\n",
    "input_dir2 = '../Database/characteristics_US'\n",
    "subdirectories = [d for d in os.listdir(input_dir)]\n",
    "\n",
    "for subdir in subdirectories:\n",
    "    base_directory = f'{input_dir}/{subdir}'\n",
    "    files = sorted(filename for filename in os.listdir(base_directory) if filename.endswith('.csv'))\n",
    "\n",
    "    dunn_dict = {}\n",
    "\n",
    "    for file in files:\n",
    "        df = read_and_preprocess_data(base_directory, file)\n",
    "        df2 = read_and_preprocess_data(input_dir2, file)\n",
    "        df2 = generate_PCA_Data(df2)\n",
    "\n",
    "        # 원본 벡터와 클러스터 레이블을 결합\n",
    "        data = df2.to_numpy()\n",
    "        labels = df['clusters'].to_numpy()\n",
    "        \n",
    "        # Dunn Index 계산\n",
    "        dunn_dict[file] = silhouette_score(data, labels)\n",
    "\n",
    "    print(subdir)\n",
    "    # 전체기간에 대하여 dunn의 평균을 구함\n",
    "    a = pd.DataFrame(dunn_dict.values()).mean()\n",
    "    print(a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T03:44:41.714375500Z",
     "start_time": "2024-06-22T03:43:23.867531300Z"
    }
   },
   "id": "1061a5a6042c046f",
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
